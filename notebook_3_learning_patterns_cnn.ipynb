{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Notebook 3: Learning Patterns - The Convolutional Neural Network (CNN)\n",
        "\n",
        "In the previous notebook, we built a Multilayer Perceptron (MLP) that classified MNIST digits by flattening the entire image into a single vector. While this works, it's not how our visual system processes images. \n",
        "\n",
        "Unlike an MLP that looks at all pixels at once, a CNN uses a small 'sliding window' (called a kernel or filter) to look for local patterns like edges, corners, and textures. This makes CNNs much more efficient and better suited for vision tasks—they can recognize the same pattern whether it appears in the top-left or bottom-right of an image. This property is called **translation invariance**, and it's one of the key reasons CNNs revolutionized computer vision.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The Core Layers of a CNN\n",
        "\n",
        "### nn.Conv2d - The Convolutional Layer\n",
        "\n",
        "The convolutional layer is the heart of a CNN. It applies a set of learnable filters (also called kernels) to the input image.\n",
        "\n",
        "**Key arguments:**\n",
        "- **`in_channels`**: Number of input channels (e.g., 1 for grayscale, 3 for RGB)\n",
        "- **`out_channels`**: Number of filters/kernels to apply (this becomes the number of output channels)\n",
        "- **`kernel_size`**: Size of the sliding window (e.g., 3 means a 3×3 filter)\n",
        "- **`padding`**: Adds zeros around the image border. `padding=1` with `kernel_size=3` keeps the output size the same as the input\n",
        "\n",
        "Each filter learns to detect a specific pattern (like vertical edges, horizontal edges, or curves). When you specify `out_channels=32`, you're creating 32 different filters, each learning to detect a different pattern.\n",
        "\n",
        "### nn.MaxPool2d - The Pooling Layer\n",
        "\n",
        "Pooling layers downsample the feature maps, reducing both computational cost and spatial dimensions. \n",
        "\n",
        "**Purpose:**\n",
        "- **Downsampling**: Reduces the height and width of feature maps (typically by a factor of 2)\n",
        "- **Translation invariance**: Makes the learned patterns more robust to small shifts in position\n",
        "- **Efficiency**: Reduces the number of parameters in subsequent layers\n",
        "\n",
        "`nn.MaxPool2d(2)` applies a 2×2 window that takes the maximum value, effectively cutting the spatial dimensions in half. For example, a 28×28 feature map becomes 14×14 after max pooling with kernel size 2.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tracing the Shapes Through the CNN\n",
        "\n",
        "Understanding how tensor shapes transform through each layer is **critical** for debugging CNNs. Let's walk through the data flow step-by-step and predict the shape at each stage.\n",
        "\n",
        "**Input**: A batch of images with shape `(64, 1, 28, 28)`.\n",
        "- 64 = batch size\n",
        "- 1 = channels (grayscale)\n",
        "- 28×28 = image dimensions\n",
        "\n",
        "**After `nn.Conv2d(1, 32, kernel_size=3, padding=1)`**: \n",
        "- The number of channels becomes 32 (we have 32 filters)\n",
        "- With `padding=1` and `kernel_size=3`, the spatial dimensions stay the same\n",
        "- Shape: `(64, 32, 28, 28)`\n",
        "\n",
        "**After `nn.ReLU()`**: \n",
        "- No shape change (element-wise operation)\n",
        "- Shape: `(64, 32, 28, 28)`\n",
        "\n",
        "**After `nn.MaxPool2d(2)`**: \n",
        "- This cuts the height and width in half\n",
        "- Channels remain 32\n",
        "- Shape: `(64, 32, 14, 14)`\n",
        "\n",
        "**After `nn.Conv2d(32, 64, kernel_size=3, padding=1)`**: \n",
        "- The number of channels becomes 64 (we now have 64 filters)\n",
        "- With padding, spatial dimensions stay the same\n",
        "- Shape: `(64, 64, 14, 14)`\n",
        "\n",
        "**After `nn.ReLU()`**: \n",
        "- No shape change\n",
        "- Shape: `(64, 64, 14, 14)`\n",
        "\n",
        "**After `nn.MaxPool2d(2)`**: \n",
        "- Height and width are cut in half again\n",
        "- Channels remain 64\n",
        "- Shape: `(64, 64, 7, 7)`\n",
        "\n",
        "**After `nn.Flatten()`**: \n",
        "- Flattens all dimensions except the batch dimension\n",
        "- Shape: `(64, 64 * 7 * 7)` = `(64, 3136)`\n",
        "\n",
        "**After `nn.Linear(3136, 128)`**: \n",
        "- Fully connected layer: 3136 → 128\n",
        "- Shape: `(64, 128)`\n",
        "\n",
        "**After `nn.ReLU()`**: \n",
        "- No shape change\n",
        "- Shape: `(64, 128)`\n",
        "\n",
        "**After `nn.Linear(128, 10)`**: \n",
        "- Final output layer: 128 → 10 (one for each digit class)\n",
        "- Shape: `(64, 10)`\n",
        "\n",
        "### Calculating in_features for the First Linear Layer\n",
        "\n",
        "After the convolutional and pooling layers, we have shape `(64, 64, 7, 7)`. When we flatten this (excluding the batch dimension), we get:\n",
        "- `64 * 7 * 7 = 3136` features\n",
        "\n",
        "This is why `nn.Linear(3136, 128)` uses `in_features=3136`—it's the product of the channel, height, and width dimensions after flattening.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training the CNN\n",
        "\n",
        "The beauty of PyTorch is its modularity. Our training logic—the loss function, the optimizer, and the training loop—remains exactly the same. We just need to pass our new CNN model to it.\n",
        "\n",
        "This demonstrates one of PyTorch's core design principles: **models are interchangeable**. You can swap out an MLP for a CNN, a ResNet, or any other architecture, and the training code stays the same. The only thing that changes is the model architecture itself.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Load the data (same as Notebook 2)\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "train_dataset = datasets.MNIST(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "test_dataset = datasets.MNIST(\n",
        "    root='./data',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "batch_size = 64\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Define the CNN\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        # First convolutional block\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "        \n",
        "        # Second convolutional block\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "        \n",
        "        # Fully connected layers\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear1 = nn.Linear(64 * 7 * 7, 128)  # 64 channels * 7 * 7 = 3136\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(128, 10)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        print(f\"Input shape: {x.shape}\")\n",
        "        \n",
        "        x = self.conv1(x)\n",
        "        print(f\"After conv1: {x.shape}\")\n",
        "        \n",
        "        x = self.relu1(x)\n",
        "        print(f\"After relu1: {x.shape}\")\n",
        "        \n",
        "        x = self.pool1(x)\n",
        "        print(f\"After pool1: {x.shape}\")\n",
        "        \n",
        "        x = self.conv2(x)\n",
        "        print(f\"After conv2: {x.shape}\")\n",
        "        \n",
        "        x = self.relu2(x)\n",
        "        print(f\"After relu2: {x.shape}\")\n",
        "        \n",
        "        x = self.pool2(x)\n",
        "        print(f\"After pool2: {x.shape}\")\n",
        "        \n",
        "        x = self.flatten(x)\n",
        "        print(f\"After flatten: {x.shape}\")\n",
        "        \n",
        "        x = self.linear1(x)\n",
        "        print(f\"After linear1: {x.shape}\")\n",
        "        \n",
        "        x = self.relu3(x)\n",
        "        print(f\"After relu3: {x.shape}\")\n",
        "        \n",
        "        x = self.linear2(x)\n",
        "        print(f\"After linear2 (output): {x.shape}\")\n",
        "        \n",
        "        return x\n",
        "\n",
        "# Instantiate the model\n",
        "model = SimpleCNN()\n",
        "print(\"Model architecture:\")\n",
        "print(model)\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Testing forward pass with one batch:\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Get one batch to test\n",
        "X, y = next(iter(train_dataloader))\n",
        "_ = model(X)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a new CNN model (without the print statements for cleaner training)\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        # First convolutional block\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "        \n",
        "        # Second convolutional block\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "        \n",
        "        # Fully connected layers\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear1 = nn.Linear(64 * 7 * 7, 128)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(128, 10)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.pool2(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.linear1(x)\n",
        "        x = self.relu3(x)\n",
        "        x = self.linear2(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the model\n",
        "model = SimpleCNN()\n",
        "\n",
        "# Instantiate loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Create a new Adam optimizer for the CNN's parameters\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Reuse the training function from Notebook 2\n",
        "def train(dataloader, model, loss_fn, optimizer, epochs=5):\n",
        "    \"\"\"\n",
        "    Train the model for a specified number of epochs.\n",
        "    \n",
        "    Args:\n",
        "        dataloader: DataLoader providing batches of training data\n",
        "        model: The neural network model\n",
        "        loss_fn: Loss function\n",
        "        optimizer: Optimizer for updating weights\n",
        "        epochs: Number of training epochs\n",
        "    \"\"\"\n",
        "    model.train()  # Set model to training mode\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0.0\n",
        "        num_batches = 0\n",
        "        \n",
        "        for batch_idx, (X, y) in enumerate(dataloader):\n",
        "            # Step 1: Forward pass\n",
        "            pred = model(X)\n",
        "            \n",
        "            # Step 2: Calculate loss\n",
        "            loss = loss_fn(pred, y)\n",
        "            \n",
        "            # Step 3: Backpropagation\n",
        "            loss.backward()\n",
        "            \n",
        "            # Step 4: Update weights\n",
        "            optimizer.step()\n",
        "            \n",
        "            # Step 5: Zero gradients\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            total_loss += loss.item()\n",
        "            num_batches += 1\n",
        "            \n",
        "            # Print progress every 100 batches\n",
        "            if (batch_idx + 1) % 100 == 0:\n",
        "                avg_loss = total_loss / num_batches\n",
        "                print(f'Epoch {epoch + 1}/{epochs}, Batch {batch_idx + 1}/{len(dataloader)}, Loss: {avg_loss:.4f}')\n",
        "        \n",
        "        # Print average loss for the epoch\n",
        "        avg_loss = total_loss / num_batches\n",
        "        print(f'Epoch {epoch + 1}/{epochs} completed. Average Loss: {avg_loss:.4f}\\n')\n",
        "\n",
        "# Train the CNN\n",
        "print(\"Starting CNN training...\\n\")\n",
        "train(train_dataloader, model, loss_fn, optimizer, epochs=5)\n",
        "print(\"Training completed!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
