{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Notebook 1: The Building Blocks - Environment & PyTorch Tensors\n",
        "\n",
        "In this notebook, we'll set up a clean, modern Python environment and master the fundamental data object in all of deep learning: the tensor. Understanding tensors is crucial—they are the foundation upon which all neural network operations are built.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Platform Disclaimer\n",
        "\n",
        "**Important:** This tutorial is designed for macOS, Linux, and Windows. The tooling (uv) is optimized for macOS and Linux. For GPU acceleration, PyTorch supports:\n",
        "- **CUDA** (NVIDIA GPUs on Linux/Windows)\n",
        "- **MPS** (Apple Silicon GPUs on macOS)\n",
        "- **CPU** (fallback for all platforms)\n",
        "\n",
        "The code will automatically detect and use the best available device.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Environment Setup\n",
        "\n",
        "We'll use `uv` as a modern, extremely fast replacement for pip and venv. It's designed to be a drop-in replacement that's orders of magnitude faster.\n",
        "\n",
        "Here are the three steps for setup:\n",
        "\n",
        "1. **Create a virtual environment:** A self-contained sandbox for our project's libraries.\n",
        "2. **Activate the environment:** \"Step inside\" the sandbox.\n",
        "3. **Install packages:** Use `uv pip install` to add our tools.\n",
        "\n",
        "Run these commands in your terminal:\n",
        "\n",
        "```bash\n",
        "# Create a virtual environment\n",
        "uv venv\n",
        "\n",
        "# Activate the environment (macOS/Linux)\n",
        "source .venv/bin/activate\n",
        "\n",
        "# Install required packages\n",
        "uv pip install torch numpy jupyter\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Introduction to Tensors\n",
        "\n",
        "What is a tensor? In the simplest terms: **It's a multi-dimensional array, like a list of lists of lists. Think of it as a super-powered NumPy array that can run on GPUs.**\n",
        "\n",
        "Tensors are the core data structure in PyTorch. We can create them in several ways:\n",
        "- From Python lists\n",
        "- From NumPy arrays\n",
        "- Using built-in functions like `torch.rand()`, `torch.ones()`, `torch.zeros()`\n",
        "- With specific values using `torch.tensor()`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# Create tensor from a Python list\n",
        "tensor_from_list = torch.tensor([1, 2, 3, 4, 5])\n",
        "print(\"From list:\", tensor_from_list)\n",
        "\n",
        "# Create tensor from a NumPy array\n",
        "numpy_array = np.array([1.0, 2.0, 3.0])\n",
        "tensor_from_numpy = torch.from_numpy(numpy_array)\n",
        "print(\"From NumPy:\", tensor_from_numpy)\n",
        "\n",
        "# Create random tensor\n",
        "random_tensor = torch.rand(3, 4)\n",
        "print(\"Random tensor:\\n\", random_tensor)\n",
        "\n",
        "# Create tensor of ones\n",
        "ones_tensor = torch.ones(2, 3)\n",
        "print(\"Ones tensor:\\n\", ones_tensor)\n",
        "\n",
        "# Create tensor of zeros\n",
        "zeros_tensor = torch.zeros(2, 3)\n",
        "print(\"Zeros tensor:\\n\", zeros_tensor)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tensor Attributes\n",
        "\n",
        "Every tensor has three critical attributes that you'll constantly check:\n",
        "\n",
        "1. **`.shape`**: The dimensions of the tensor. This is the most critical concept for debugging models—mismatched shapes are the #1 cause of errors.\n",
        "2. **`.dtype`**: The data type (e.g., `float32`, `int64`, `long`). Determines how much memory is used and what operations are allowed.\n",
        "3. **`.device`**: Where the tensor lives (e.g., `'cpu'`, `'cuda'`, or `'mps'`). This determines whether computations run on CPU or GPU.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a tensor and inspect its attributes\n",
        "example_tensor = torch.rand(3, 4, 5)\n",
        "\n",
        "print(\"Tensor shape:\", example_tensor.shape)\n",
        "print(\"Tensor dtype:\", example_tensor.dtype)\n",
        "print(\"Tensor device:\", example_tensor.device)\n",
        "print(\"\\nFull tensor:\\n\", example_tensor)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The Art of Shaping Data\n",
        "\n",
        "Tensor operations are the core skill for a code-first deep learning practitioner. Being able to manipulate and reshape tensors is essential for preparing data for your models.\n",
        "\n",
        "Standard indexing and slicing works just like NumPy—if you're familiar with NumPy, you already know how to do this in PyTorch.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a 4x4 tensor\n",
        "matrix = torch.arange(16).reshape(4, 4)\n",
        "print(\"Original 4x4 tensor:\\n\", matrix)\n",
        "\n",
        "# Slice the first row\n",
        "first_row = matrix[0, :]\n",
        "print(\"\\nFirst row:\", first_row)\n",
        "\n",
        "# Slice the first column\n",
        "first_column = matrix[:, 0]\n",
        "print(\"First column:\", first_column)\n",
        "\n",
        "# Slice the last column\n",
        "last_column = matrix[:, -1]\n",
        "print(\"Last column:\", last_column)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reshaping with view()\n",
        "\n",
        "The `.view()` method is incredibly powerful—it reshapes a tensor without copying the data. It's a \"free\" operation that just creates a new view of the same underlying data.\n",
        "\n",
        "The `-1` trick is particularly useful: it tells PyTorch to automatically infer that dimension based on the total number of elements. For example, if you have a tensor with 12 elements and call `.view(3, -1)`, PyTorch will automatically make it `(3, 4)`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a tensor with initial shape\n",
        "original = torch.arange(12)\n",
        "print(\"Original shape:\", original.shape)\n",
        "print(\"Original tensor:\", original)\n",
        "\n",
        "# Reshape using view with -1 trick\n",
        "reshaped = original.view(2, -1)\n",
        "print(\"\\nReshaped to (2, -1):\\n\", reshaped)\n",
        "print(\"New shape:\", reshaped.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Adding and Removing Dimensions\n",
        "\n",
        "`unsqueeze()` and `squeeze()` are essential for managing tensor dimensions. The most common practical use case: **You will use `unsqueeze(0)` constantly to add a 'batch' dimension to a single data point before feeding it to a model.**\n",
        "\n",
        "- `unsqueeze(dim)`: Adds a dimension of size 1 at the specified position\n",
        "- `squeeze(dim)`: Removes a dimension of size 1 at the specified position (or all size-1 dimensions if no dim specified)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a tensor\n",
        "tensor = torch.tensor([1, 2, 3, 4, 5])\n",
        "print(\"Original shape:\", tensor.shape)\n",
        "print(\"Original tensor:\", tensor)\n",
        "\n",
        "# Add a dimension at position 0 (adds batch dimension)\n",
        "with_batch = tensor.unsqueeze(0)\n",
        "print(\"\\nAfter unsqueeze(0):\")\n",
        "print(\"Shape:\", with_batch.shape)\n",
        "print(\"Tensor:\\n\", with_batch)\n",
        "\n",
        "# Remove the dimension we just added\n",
        "back_to_original = with_batch.squeeze(0)\n",
        "print(\"\\nAfter squeeze(0):\")\n",
        "print(\"Shape:\", back_to_original.shape)\n",
        "print(\"Tensor:\", back_to_original)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CPU vs. GPU Acceleration\n",
        "\n",
        "Large computations are much faster on a GPU. PyTorch supports multiple GPU backends:\n",
        "- **CUDA**: For NVIDIA GPUs (Linux/Windows)\n",
        "- **MPS**: For Apple Silicon GPUs (macOS)\n",
        "- **CPU**: Fallback for all platforms\n",
        "\n",
        "In the next cell, we'll:\n",
        "1. Detect the best available device (CUDA → MPS → CPU)\n",
        "2. Create two large tensors\n",
        "3. Time a matrix multiplication on the CPU\n",
        "4. Move them to the GPU device using `.to(device)` (if available)\n",
        "5. Time the same operation on GPU\n",
        "\n",
        "You should see a significant speedup on GPU for large operations!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "# Detect the best available device: CUDA → MPS → CPU\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"CUDA is available! Using GPU: {torch.cuda.get_device_name(0)}\")\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = torch.device(\"mps\")\n",
        "    print(\"MPS is available! Using Apple Silicon GPU.\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"No GPU available. Using CPU.\")\n",
        "\n",
        "size = 2000\n",
        "a_cpu = torch.rand(size, size)\n",
        "b_cpu = torch.rand(size, size)\n",
        "\n",
        "# Time CPU computation\n",
        "start_time = time.time()\n",
        "result_cpu = torch.matmul(a_cpu, b_cpu)\n",
        "cpu_time = time.time() - start_time\n",
        "print(f\"\\nCPU time: {cpu_time:.4f} seconds\")\n",
        "\n",
        "# Time GPU computation if available\n",
        "if device.type != \"cpu\":\n",
        "    a_gpu = a_cpu.to(device)\n",
        "    b_gpu = b_cpu.to(device)\n",
        "    \n",
        "    # Warm up (first operation can be slower)\n",
        "    _ = torch.matmul(a_gpu, b_gpu)\n",
        "    \n",
        "    start_time = time.time()\n",
        "    result_gpu = torch.matmul(a_gpu, b_gpu)\n",
        "    gpu_time = time.time() - start_time\n",
        "    print(f\"{device.type.upper()} time: {gpu_time:.4f} seconds\")\n",
        "    print(f\"Speedup: {cpu_time/gpu_time:.2f}x faster\")\n",
        "else:\n",
        "    print(\"No GPU available - skipping GPU comparison\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
